question,answer
"What is RAG?","Retrieval-Augmented Generation combines information retrieval and text generation to produce grounded responses."
"How does RAG improve LLM accuracy?","RAG retrieves relevant documents before generation, reducing hallucinations and improving factual correctness."
"What is NLP?","Natural Language Processing enables machines to understand, interpret, and generate human language."
"What is an LLM?","A Large Language Model is a neural network trained on massive text data to generate human-like language."
"Why do LLMs hallucinate?","LLMs hallucinate because they generate text based on probability rather than verified external knowledge."
"How does RAG reduce hallucination?","RAG provides factual retrieved context to the LLM before generating a response."
"What is a vector database?","A vector database stores vector embeddings for fast similarity search."
"Name popular vector databases","Pinecone, FAISS, ChromaDB, Weaviate, and Azure AI Search are popular vector databases."
"What are embeddings?","Embeddings are numerical vector representations of text capturing semantic meaning."
"Why are embeddings used in RAG?","They allow semantic similarity search to retrieve relevant documents."
"What is semantic search?","Semantic search retrieves results based on meaning rather than exact keyword match."
"What is chunking in RAG?","Chunking is splitting large documents into smaller parts for better retrieval accuracy."
"What is top-k retrieval?","Top-k retrieval returns the k most similar document chunks for a query."
"What is a knowledge base in RAG?","A knowledge base is a collection of embedded documents stored for retrieval."
"What is prompt augmentation?","Prompt augmentation inserts retrieved text into the LLM prompt before generation."
"What is a retriever in RAG?","A retriever searches the vector database to find relevant content."
"What is a generator in RAG?","The generator is the LLM that produces the final answer using retrieved context."
"What is FAISS?","FAISS is an open-source library by Meta for fast vector similarity search."
"What is Pinecone?","Pinecone is a managed cloud vector database service."
"What is ChromaDB?","ChromaDB is an open-source vector database used for local RAG applications."
"What is Azure AI Search?","Azure AI Search is a cloud-based search service that supports vector and hybrid search."
"What is hybrid search?","Hybrid search combines keyword search with vector similarity search."
"What is the knowledge cutoff problem?","LLMs have a fixed training data cutoff and cannot know recent events."
"How does RAG solve knowledge cutoff?","RAG retrieves real-time or updated external data at query time."
"What is fine-tuning?","Fine-tuning is training an LLM further on domain-specific data."
"RAG vs Fine-tuning","RAG retrieves external knowledge dynamically while fine-tuning embeds knowledge into model weights."
"Which is easier to update RAG or fine-tuning?","RAG is easier to update because only the document store changes."
"What is a chatbot?","A chatbot is a program that interacts with users through natural language."
"How is RAG used in chatbots?","RAG enables chatbots to answer using enterprise or external knowledge bases."
"What is an enterprise knowledge assistant?","It is an AI system that answers employee queries using internal documents."
"What is document ingestion in RAG?","It is the process of loading and embedding documents into a vector database."
"What is similarity search?","Similarity search finds vectors that are close in embedding space."
"What distance metric is used in FAISS?","FAISS commonly uses L2 or cosine distance for similarity search."
"What is cosine similarity?","Cosine similarity measures the angle between two vectors to determine semantic closeness."
"What is context window in LLMs?","The context window is the maximum text length an LLM can process at once."
"Why is chunk size important?","Proper chunk size ensures relevant retrieval without exceeding context limits."
"What is RAG summarization?","It retrieves relevant text chunks and generates a concise summary."
"What is RAG-based QA?","It retrieves knowledge documents and generates answers grounded in them."
"What is LangChain?","LangChain is a framework for building LLM applications including RAG pipelines."
"What is LlamaIndex?","LlamaIndex is a data framework for connecting custom data to LLMs."
"What is a prompt template?","A prompt template is a structured format for sending instructions to LLMs."
"What is context injection?","Context injection inserts retrieved documents into the LLM prompt."
"What is grounding in AI?","Grounding ensures AI responses are based on real data sources."
"Why is grounding important?","It increases trust and reduces misinformation."
"What is an AI hallucination?","An AI hallucination is a confident but incorrect generated response."
"What is enterprise RAG?","Enterprise RAG connects LLMs to internal business documents securely."
"What is conversational RAG?","Conversational RAG maintains chat history while retrieving knowledge."
"What is multi-hop RAG?","Multi-hop RAG performs multiple retrieval steps to answer complex queries."
"What is agentic RAG?","Agentic RAG allows LLMs to decide when and how to retrieve information."
"What are common RAG use cases?","Customer support bots, document search, compliance assistants, and research tools."
